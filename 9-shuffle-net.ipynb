{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35d940ef-0d53-431d-9e2c-f4dc5d0f02bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image_dir ='/Workspace/sid-v2/computervision1/Classification_dataset_v3/images/train'\n",
    "for label, class_dir in enumerate(os.listdir(image_dir)):\n",
    "    print(label,class_dir)\n",
    "\n",
    "class generate_image_dataset(Dataset):\n",
    "    def __init__(self,image_dir, transform=None):\n",
    "        self.image_dir=image_dir\n",
    "        self.image_paths=[]\n",
    "        self.labels=[]\n",
    "        self.class_name={}\n",
    "        self.transform = transform\n",
    "\n",
    "        for label, class_dir in enumerate(os.listdir(image_dir)):\n",
    "            self.class_name[label] =class_dir\n",
    "            class_path = os.path.join(image_dir,class_dir)\n",
    "            for img_name in os.listdir(class_path):\n",
    "                self.image_paths.append(os.path.join(class_path,img_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')     \n",
    "        label = self.labels[idx]             \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)     \n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Updated transform for ShuffleNet (ImageNet normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ShuffleNet typically uses 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "train_image_dir ='/Workspace/sid-v2/computervision1/Classification_dataset_v3/images/train'\n",
    "test_image_dir ='/Workspace/sid-v2/computervision1/Classification_dataset_v3/images/test'\n",
    "\n",
    "training_image_dataset = generate_image_dataset(image_dir=train_image_dir,transform=transform)\n",
    "test_image_dataset = generate_image_dataset(image_dir=test_image_dir,transform=transform)\n",
    "\n",
    "train_image_loader = DataLoader(dataset=training_image_dataset, batch_size=32,shuffle=True)\n",
    "test_image_loader = DataLoader(dataset=test_image_dataset, batch_size=32,shuffle=True)\n",
    "\n",
    "for images, labels in train_image_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "\n",
    "# Visualization (adjust for ImageNet normalization)\n",
    "for images, labels in train_image_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    img = images[0].numpy()\n",
    "    label = labels[0].item()\n",
    "\n",
    "    print(training_image_dataset.class_name[label])\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    \n",
    "    # Denormalize for visualization\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = img * std + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    print(img.shape)\n",
    "    print(label)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    break\n",
    "\n",
    "# ShuffleNet Model Setup\n",
    "def create_shufflenet_model(num_classes=3, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create ShuffleNet v2 model with custom number of classes\n",
    "    \"\"\"\n",
    "    # Load pre-trained ShuffleNet v2 (1.0x variant)\n",
    "    model = models.shufflenet_v2_x1_0(pretrained=pretrained)\n",
    "    \n",
    "    # Get the number of input features to the final classifier\n",
    "    num_features = model.fc.in_features\n",
    "    \n",
    "    # Replace the final classifier layer for your number of classes\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Alternative: Create ShuffleNet from scratch (no pre-training)\n",
    "def create_shufflenet_no_pretrain(num_classes=3):\n",
    "    \"\"\"\n",
    "    Create ShuffleNet v2 model without pre-training\n",
    "    \"\"\"\n",
    "    model = models.shufflenet_v2_x1_0(pretrained=False, num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model - choose one of the following:\n",
    "\n",
    "# Option 1: Pre-trained ShuffleNet (recommended for better performance)\n",
    "model = create_shufflenet_model(num_classes=3, pretrained=True).to(device)\n",
    "\n",
    "# Option 2: ShuffleNet from scratch (uncomment to use)\n",
    "# model = create_shufflenet_no_pretrain(num_classes=3).to(device)\n",
    "\n",
    "print(f\"Model created: {model.__class__.__name__}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 2\n",
    "\n",
    "# Training loop\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_image_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:  # Print every 10 batches\n",
    "            print(f'Epoch {i+1}/{epochs}, Batch {batch_idx}/{len(train_image_loader)}, '\n",
    "                  f'Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {i+1}/{epochs}, Average Loss: {running_loss/len(train_image_loader):.4f}, \"\n",
    "          f\"Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_image_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "print(f\"Test Loss: {test_loss/len(test_image_loader):.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"Architecture: ShuffleNet v2 1.0x\")\n",
    "print(f\"Input size: 224x224x3\")\n",
    "print(f\"Number of classes: 3\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Model size: ~2.3M parameters\")\n",
    "print(f\"Expected inference speed: ~10ms on mobile CPU\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "9-shuffle-net",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
